struct CallbackEntry {
    uint32_t code[4];
};

struct CallbackDataEntry {
    uint64_t target;
    uint64_t trampoline;
};

#define LDRLIT(reg, lit) ((0b01011000 << 24) | (((lit) >> 2) << 5) | (reg))

static uint32_t cbtrampoline[4] = {
    LDRLIT(16, MAXCALLBACKS * sizeof(struct CallbackEntry)), // ldr x16, .+X
    LDRLIT(18, 4 + MAXCALLBACKS * sizeof(struct CallbackEntry)), // ldr x18, .+X+4
    0xd61f0240, // br x18
    0xd503201f, // nop
};

_Static_assert(sizeof(struct CallbackDataEntry) == sizeof(struct CallbackEntry), "Wrong CallbackEntry size");
_Static_assert(MAXCALLBACKS * sizeof(struct CallbackEntry) % 16384 == 0, "Invalid MAXCALLBACKS");

static struct CallbackDataEntry* dataentries_alias;
static struct CallbackDataEntry* dataentries_box;

static struct CallbackEntry* cbentries_alias;
static struct CallbackEntry* cbentries_box;

static bool
cbinit(struct LFIContext* ctx)
{
    int fd = memfd_create("", 0);
    if (fd < 0)
        return false;
    size_t size = 2 * MAXCALLBACKS * sizeof(struct CallbackEntry);
    int r = ftruncate(fd, size);
    if (r < 0)
        goto err;
    // Map callback entries outside the sandbox as read/write.
    void* aliasmap = mmap(NULL, size, PROT_READ | PROT_WRITE, MAP_SHARED, fd, 0);
    if (aliasmap == (void*) -1)
        goto err;
    cbentries_alias = (struct CallbackEntry*) aliasmap;
    dataentries_alias = (struct CallbackDataEntry*) (aliasmap + size / 2);
    // Fill in the code for each entry.
    for (size_t i = 0; i < MAXCALLBACKS; i++) {
        memcpy(&cbentries_alias[i].code, &cbtrampoline[0], sizeof(cbentries_alias[i].code));
    }
    struct HostFile* hf = lfi->lfi_host_fdopen(fd);
    assert(hf);
    // Share the mapping inside the sandbox as read/exec.
    lfiptr_t boxmap = lfi->lfi_as_mapany(lfi->lfi_ctx_as(ctx), size, PROT_READ, MAP_SHARED, hf, 0);
    if (boxmap == (lfiptr_t) -1)
        goto err1;
    // map the code page as executable
    int ok = lfi->lfi_as_mprotect(lfi->lfi_ctx_as(ctx), boxmap, size / 2, PROT_READ | PROT_EXEC);
    // TODO: maybe ignore verification failures here since this code region is hand-crafted
    assert(ok == 0);
    cbentries_box = (struct CallbackEntry*) boxmap;
    dataentries_box = (struct CallbackDataEntry*) (boxmap + size / 2);
    return true;
err1:
    munmap(aliasmap, size);
err:
    close(fd);
    return false;
}

void*
{{ .lib }}_register_cb(void* fn, size_t stackframe)
{
    assert(fn);
    assert(cbfind(fn) == -1 && "fn is already registered as a callback");

    ssize_t slot = cbfreeslot();
    if (slot == -1)
        return NULL;

    // TODO: support non-zero stackframes: create a trampoline for 'stackframe'
    // if it does not exist
    if (stackframe != 0)
        return NULL;

    // write 'fn' into the 'target' field for the chosen slot.
    __atomic_store_n(&dataentries_alias[slot].target, (uint64_t) fn, __ATOMIC_SEQ_CST);
    // write the trampoline into the 'trampoline' field for the chosen slot
    __atomic_store_n(&dataentries_alias[slot].trampoline, (uint64_t) {{.lib}}_cbtrampoline, __ATOMIC_SEQ_CST);

    // Mark the slot as allocated.
    callbacks[slot] = fn;

    return &cbentries_box[slot].code[0];
}

void
{{ .lib }}_unregister_cb(void* fn)
{
    ssize_t slot = cbfind(fn);
    if (slot == -1)
        return;
    callbacks[slot] = NULL;
    __atomic_store_n(&dataentries_alias[slot].target, 0, __ATOMIC_SEQ_CST);
    __atomic_store_n(&dataentries_alias[slot].trampoline, 0, __ATOMIC_SEQ_CST);
}

void*
{{ .lib }}_addr(void* sym)
{
    const size_t trampoline_size = 16;
    for (size_t i = 0; i < __lfi_trampotable_size; i++) {
        if (&__lfi_trampolines[i * trampoline_size] == sym)
            return __lfi_trampotable[i];
    }
    return NULL;
}
