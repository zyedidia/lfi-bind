.section ".text.trampolines"

.macro pushx xmm
	subq $16, %rsp
	movdqu \xmm, (%rsp)
.endm

.macro popx xmm
	movdqu (%rsp), \xmm
	addq $16, %rsp
.endm

.macro get_ctx
#ifndef NODLOPEN
    movq lfi@GOTPCREL(%rip), %rax
    movq (%rax), %rax // %rax now points to struct LFI
    movq (%rax), %rax // %rax now points to lfi_ctx_fn
    leaq 1f(%rip), %r11
    jmpq *%rax
1:
    // context pointer is now in %rax
    movq %rax, %r11
#else
    movq lfi_myctx@gottpoff(%rip), %r11
    movq %fs:(%r11), %r11
#endif
.endm

.globl lfi_ctx
lfi_ctx:
    movq lfi@GOTPCREL(%rip), %rax
    movq (%rax), %rax // %rax now points to struct LFI
    movq (%rax), %rax // %rax now points to lfi_ctx_fn
    leaq 1f(%rip), %r11
    jmpq *%rax
1:
    // context pointer is now in %rax
    ret

.lfi_trampoline_slowpath:
	# slow path
	pushq %rdi
	pushq %rsi
	pushq %rdx
	pushq %rcx
	pushq %r8
	pushq %r9
	pushq %r10
	pushq %r11
	pushx %xmm0
	pushx %xmm1
	pushx %xmm2
	pushx %xmm3
	pushx %xmm4
	pushx %xmm5
	pushx %xmm6
	pushx %xmm7
	callq {{.lib}}_setup
	popx %xmm0
	popx %xmm1
	popx %xmm2
	popx %xmm3
	popx %xmm4
	popx %xmm5
	popx %xmm6
	popx %xmm7
	popq %r11
	popq %r10
	popq %r9
	popq %r8
	popq %rcx
	popq %rdx
	popq %rsi
	popq %rdi
    get_ctx
	ret

.global __lfi_trampoline_stack
__lfi_trampoline_stack:
.lfi_trampoline_stack:
    pushq %r15
    pushq %r14
    pushq %r13
    pushq %r12
    pushq %rbx
    pushq %rbp
    get_ctx

    cmpq $0, %r11
    jne 1f
    call .lfi_trampoline_slowpath
1:

    pushq %rbp     // dummy push to keep stack properly aligned
    pushq 16(%r11) // push user stack value
    movq %rsp, 0(%r11) # kstackp
    movq 16(%r11), %rsp # stack pointer
    movq 16+14*8(%r11), %r14 # base pointer
#ifndef SINGLEBOX
    wrgsbase %r14  // TODO: maybe we can get away with skipping this
#endif
#ifdef LARGEBOX
    movq 16+15*8(%r11), %r15
#endif
    mov __lfisym__lfi_retfn@GOTPCREL(%rip), %r11
    mov (%r11), %r11
    andq $0xfffffffffffffff0, %rsp
    pushq %r11
    xor %r11d, %r11d
    # TODO: make sure r10 is bundle-aligned and within the sandbox
.entry_stack:
    jmpq *%r10
    int3

.global __lfi_trampoline
__lfi_trampoline:
.lfi_trampoline:
	pushq %r15
	pushq %r14
	pushq %r13
	pushq %r12
	pushq %rbx
	pushq %rbp
    get_ctx

	cmpq $0, %r11
	jne 1f
	call .lfi_trampoline_slowpath
1:

    pushq %rbp     // dummy push to keep stack properly aligned
    pushq 16(%r11) // push user stack value
	movq %rsp, 0(%r11) # kstackp
	movq 16(%r11), %rsp # stack pointer
	movq 16+14*8(%r11), %r14 # base pointer
#ifndef SINGLEBOX
    wrgsbase %r14  // TODO: maybe we can get away with skipping this
#endif
#ifdef LARGEBOX
    movq 16+15*8(%r11), %r15
#endif
	mov __lfisym__lfi_retfn@GOTPCREL(%rip), %r11
	mov (%r11), %r11
	andq $0xfffffffffffffff0, %rsp
    // this push could segfault is the user stack is bad
userpush:
	pushq %r11
	xor %r11d, %r11d
	// TODO: make sure r10 is bundle-aligned and within the sandbox
.entry:
	jmpq *%r10
	int3

.global __lfi_trampolines
__lfi_trampolines:
{{- range $sym := .exported }}
.p2align 4
.global {{$sym}}
{{$sym}}:
	movq jni_env@GOTPCREL(%rip), %r10
	movq %rdi, (%r10)
	movq jni_proxy@GOTPCREL(%rip), %r10
	movq (%r10), %rdi
	movq __lfisym_{{$sym}}@GOTPCREL(%rip), %r10
	movq (%r10), %r10
    {{if (has_stack_args $sym)}}
	jmp .lfi_trampoline_stack
    {{else}}
    jmp .lfi_trampoline
    {{end}}
{{- end}}

{{- range $sym := .exposed}}
.p2align 4
.global {{$.lib}}_{{$sym}}
{{$.lib}}_{{$sym}}:
	movq __lfisym_{{$sym}}@GOTPCREL(%rip), %r10
	movq (%r10), %r10
    {{if (has_stack_args $sym)}}
    jmp .lfi_trampoline_stack
    {{else}}
    jmp .lfi_trampoline
    {{end}}
{{- end}}

.section ".data.trampolines"

.global __lfi_trampotable
__lfi_trampotable:

{{- range $sym := .exported}}
.global __lfisym_{{$sym}}
__lfisym_{{$sym}}:
	.quad 0
{{- end}}

{{- range $sym := .exposed}}
.global __lfisym_{{$sym}}
__lfisym_{{$sym}}:
	.quad 0
{{- end}}

.global __lfi_trampotable_size
__lfi_trampotable_size:
	.quad {{.nexported}}+{{.nexposed}}

.global __lfisym__lfi_pause
.global __lfisym__lfi_thread_create

.section .note.GNU-stack,"",@progbits
